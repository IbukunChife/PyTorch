{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Y5uSvTjhvHgX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from skimage import io, transform\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.ion()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GfSyc8lU1FzE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FaceLandmarkDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, csv_file, github_url, transform=None):\n",
        "        \n",
        "        self.landmarks_frame = pd.read_csv(github_url+csv_file)\n",
        "        self.github_url = github_url\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.landmarks_frame)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_url = self.github_url+self.landmarks_frame.iloc[idx, 0]\n",
        "        \n",
        "        image = io.imread(img_url)\n",
        "        landmarks = landmarks_frame.iloc[idx, 1:].as_matrix()\n",
        "        landmarks = landmarks.astype('float').reshape(-1,2)\n",
        "        sample = {'image' : image, 'landmarks': landmarks}\n",
        "        \n",
        "        if self.transform:\n",
        "            self.transform(sample)\n",
        "            \n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dvggt4pb9cdc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Rescale(object):\n",
        "    \n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        self.output_size = output_size\n",
        "        \n",
        "    def __call__(self, sample):\n",
        "        image, landmarks = sample['image'], sample['landmarks']\n",
        "        \n",
        "        h, w = image.shape[:2]\n",
        "        if isinstance(self.output_size, int):\n",
        "            if h > w:\n",
        "                new_h, new_w = self.output_size * h / w, self.output_size\n",
        "            else:\n",
        "                new_h, new_w = self.output_size, self.output_size * w / h\n",
        "        else:\n",
        "            new_h, new_w = self.output_size\n",
        "            \n",
        "        new_h, new_w = int(new_h), int(new_w)\n",
        "        \n",
        "        img = transform.resize(image, (new_h, new_w))\n",
        "        \n",
        "        landmarks = landmarks * [new_w / w, new_h / h]\n",
        "\n",
        "        return {'image': img, 'landmarks': landmarks}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oaKgTSPIDwbD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RandomCrop(object):\n",
        "    \n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        if isinstance(output_size, int):\n",
        "            self.output_size = (output_size, output_size)\n",
        "        else:\n",
        "            assert len(output_size) == 2\n",
        "            self.output_size = output_size\n",
        "            \n",
        "    def __call__(self, sample):\n",
        "        image, landmarks = sample['image'], sample['landmarks']\n",
        "        \n",
        "        h, w = image.shape[:2]\n",
        "        \n",
        "        new_h, new_w = self.output_size\n",
        "        \n",
        "        top=np.random.randint(0, h - new_h)\n",
        "        left = np.random.randint(0, w - new_w)\n",
        "        \n",
        "        image = image[top: top + new_h,\n",
        "                      left: left+ new_w]\n",
        "        \n",
        "        landmarks = landmarks - [left, top]\n",
        "        \n",
        "        return {'image': image, 'landmarks': landmarks}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k0ZWkjnGEaz1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ToTensor(object):\n",
        "    \n",
        "    def __call__(self, sample):\n",
        "        image, landmarks = sample['image'], sample['landmarks']\n",
        "        \n",
        "        image = image.transpose((2,0,1))\n",
        "        return {'image': torch.from_numpy(image), \n",
        "                'landmarks': torch.from_numpy(landmarks)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rKr9pWXcxsjg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_landmarks(image, landmarks):\n",
        "    plt.imshow(image)\n",
        "    \n",
        "    plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker='*', color='r')\n",
        "    plt.pause(0.001)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GHsdVrNBzYtC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "github_url = 'https://raw.githubusercontent.com/CameronTaylorFL/PyTorch/master/faces/' \n",
        "csv_file = 'face_landmarks.csv'\n",
        "\n",
        "data_set = FaceLandmarkDataset(csv_file=csv_file, github_url=github_url)\n",
        "\n",
        "scale = Rescale(256)\n",
        "crop = RandomCrop(128)\n",
        "\n",
        "composed = transforms.Compose([Rescale(256),\n",
        "                               RandomCrop(224)])\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "sample = data_set[65]\n",
        "\n",
        "for i, tsfrm in enumerate([scale, crop, composed]):\n",
        "    transformed_sample = tsfrm(sample)\n",
        "    \n",
        "    ax = plt.subplot(1, 4, i+1)\n",
        "    plt.tight_layout()\n",
        "    ax.set_title(type(tsfrm).__name__)\n",
        "    show_landmarks(**transformed_sample)\n",
        "\n",
        "show_landmarks(**sample)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}